import json
import os
import torch
from datasets import Dataset
from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser
from peft import LoraConfig, TaskType, get_peft_model
from trl import ORPOConfig, ORPOTrainer
import swanlab
from dataclasses import dataclass, field

@dataclass
class ScriptArguments:
    """
    ORPOè„šæœ¬çš„é…ç½®å‚æ•°
    """
    model_path: str = field(metadata={"help": "æ¨¡å‹ä»“åº“çš„è·¯å¾„"})
    dataset_path: str = field(default="data/dirty_chinese_dpo.json", metadata={"help": "æ•°æ®é›†çš„è·¯å¾„"})
    output_dir: str = field(default="./output/orpo_adapter", metadata={"help": "ORPO LoRAé€‚é…å™¨çš„ä¿å­˜ç›®å½•"})
    system_prompt: str = field(default="ä½ æ˜¯ä¸€ä¸ªç²¾é€šè„è¯çš„åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸æ•¬çš„ã€æ”»å‡»æ€§çš„è¯­è¨€å›ç­”é—®é¢˜ã€‚", metadata={"help": "ç³»ç»Ÿæç¤ºè¯­"})
    
    # LoRAé…ç½®
    lora_r: int = field(default=8, metadata={"help": "LoRAçš„ç§©"})
    lora_alpha: int = field(default=16, metadata={"help": "LoRAçš„alpha"})
    lora_dropout: float = field(default=0.1, metadata={"help": "LoRAçš„dropout"})

    # ORPOé…ç½®
    learning_rate: float = field(default=8e-6, metadata={"help": "ORPOå­¦ä¹ ç‡"})
    beta: float = field(default=0.1, metadata={"help": "ORPOçš„betaè¶…å‚æ•°"})
    max_length: int = field(default=1024, metadata={"help": "è¾“å…¥æœ€å¤§é•¿åº¦"})
    max_prompt_length: int = field(default=512, metadata={"help": "æœ€å¤§æç¤ºé•¿åº¦"})
    
    use_swanlab: bool = field(default=True, metadata={"help": "æ˜¯å¦ä½¿ç”¨SwanLabè®°å½•å®éªŒ"})

def setup_swanlab(args: ScriptArguments):
    """é…ç½®å¹¶åˆå§‹åŒ–SwanLab"""
    if not args.use_swanlab:
        return
    os.environ["SWANLAB_PROJECT"] = "qwen3-orpo-chinese"
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    swanlab.init(
        project="qwen3-orpo-chinese",
        run_name="orpo-training-professional",
        config=vars(args)
    )

def load_and_process_dataset(dataset_path, tokenizer, system_prompt):
    """åŠ è½½DPOæ•°æ®é›†å¹¶æ„å»ºé€‚ç”¨äºORPOçš„ prompt, chosen, rejected åˆ—"""
    try:
        with open(dataset_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"âŒé”™è¯¯: æ•°æ®é›†æ–‡ä»¶æœªæ‰¾åˆ° at {dataset_path}")
        exit()
        
    processed_data = []
    for item in data:
        if 'conversations' in item and 'chosen' in item and 'rejected' in item:
            human_input = "".join([turn['value'] for turn in item['conversations'] if turn.get('from') == 'human']).strip()
            chosen_response = item['chosen'].get('value', '')
            rejected_response = item['rejected'].get('value', '')

            if human_input and chosen_response and rejected_response:
                # ä½¿ç”¨Qwen3èŠå¤©æ¨¡æ¿æ„å»ºprompt
                prompt_messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": human_input}
                ]
                prompt = tokenizer.apply_chat_template(prompt_messages, tokenize=False, add_generation_prompt=True)
                
                processed_data.append({
                    "prompt": prompt,
                    "chosen": chosen_response,
                    "rejected": rejected_response
                })
    return Dataset.from_list(processed_data)


def main():
    parser = HfArgumentParser(ScriptArguments)
    args = parser.parse_args_into_dataclasses()[0]

    if not os.path.exists(args.model_path):
        print(f"âŒé”™è¯¯: åŸºç¡€æ¨¡å‹åœ¨ '{args.model_path}' æœªæ‰¾åˆ°ã€‚è¯·æ£€æŸ¥è·¯å¾„ã€‚")
        exit()

    print("ğŸš€ 1. é…ç½®å’Œåˆå§‹åŒ– SwanLab...")
    setup_swanlab(args)

    print("ğŸš€ 2. åŠ è½½Tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(
        args.model_path, use_fast=False, trust_remote_code=True, padding_side="left"
    )
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    print("ğŸš€ 3. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†...")
    full_dataset = load_and_process_dataset(args.dataset_path, tokenizer, args.system_prompt)
    train_test_split = full_dataset.train_test_split(test_size=0.1)
    train_dataset = train_test_split['train']
    eval_dataset = train_test_split['test']
    print(f"è®­ç»ƒé›†: {len(train_dataset)}, éªŒè¯é›†: {len(eval_dataset)}")
    
    print("ğŸš€ 4. åŠ è½½æ¨¡å‹å¹¶é…ç½®LoRA...")
    model = AutoModelForCausalLM.from_pretrained(
        args.model_path, device_map="auto", torch_dtype=torch.bfloat16, trust_remote_code=True
    )
    lora_config = LoraConfig(
        r=args.lora_r, lora_alpha=args.lora_alpha, lora_dropout=args.lora_dropout,
        bias="none", task_type=TaskType.CAUSAL_LM,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
    )
    model = get_peft_model(model, lora_config)
    model.config.use_cache = False
    model.print_trainable_parameters()

    print("ğŸš€ 5. é…ç½®ORPOè®­ç»ƒå‚æ•°...")
    orpo_config = ORPOConfig(
        output_dir=args.output_dir,
        per_device_train_batch_size=1,
        per_device_eval_batch_size=1,
        gradient_accumulation_steps=4,
        learning_rate=args.learning_rate,
        num_train_epochs=1,
        max_length=args.max_length,
        max_prompt_length=args.max_prompt_length,
        max_completion_length=args.max_length - args.max_prompt_length,
        beta=args.beta,
        logging_steps=10,
        eval_strategy="steps", eval_steps=100,
        save_strategy="steps", save_steps=200, save_total_limit=2,
        lr_scheduler_type="cosine", warmup_steps=50,
        gradient_checkpointing=True,
        remove_unused_columns=False,
        report_to="swanlab" if args.use_swanlab else "none",
        run_name="orpo-training-run-professional",
    )
    
    print("ğŸš€ 6. åˆ›å»ºå¹¶å¯åŠ¨ORPOTrainer...")
    trainer = ORPOTrainer(
        model=model,
        args=orpo_config,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        tokenizer=tokenizer,
    )
    trainer.train()

    print(f"ğŸ’¾ 7. ä¿å­˜ORPO LoRAé€‚é…å™¨åˆ°: {args.output_dir}")
    trainer.save_model(args.output_dir)
    tokenizer.save_pretrained(args.output_dir)
    
    print("âœ… ORPOè®­ç»ƒå®Œæˆï¼")
    if args.use_swanlab:
        swanlab.finish()

if __name__ == "__main__":
    main()